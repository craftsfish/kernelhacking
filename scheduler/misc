The RT class supports the SCHED_RR and SCHED_FIFO policies, and the CFS class supports SCHED_NORMAL and SCHED_BATCH.


一个task隶属于一个特定的scheduler class
一个scheduler class可以同时支持多种scheduling policy，所以在task结构中存储了具体的scheduling policy


一个rq如何管理多个scheduler class
每个CPU有一个rq, DECLARE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
一个rq里面包含了rt, cfs, dl三个特定的rq
scheduler_tick函数只负责更新状态，并检查当前task是否需要被抢占, 实际的切换在schedule中执行
schedule函数调用pick_next_task，依次执行各scheduler class，选出下一个需要执行的task


vruntime = 具体的执行时间 / 优先级权重


cfs调度要在一个sysctl_sched_latency周期内确保每个active task至少被调度到一次
cfs里面的leftmost task指的是当前vruntime最小的task，可能是current或者rb_leftmost
wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se) se是否需要抢占curr {
	curr->vruntime < se->vruntime, 返回-1，让curr运行
	curr->vruntime - se->vruntime <= wakeup_gran, 返回0，curr比se多运行的时间没有超过1个gran身位，让curr运行
	curr->vruntime - se->vruntime >  wakeup_gran, 返回1，curr比se多运行的时间超过1个gran身位，让se运行
}


struct task_group通过 {
	task_group *parent;
	list_head siblings;
	list_head children;
}维护了一个树状结构，为了支持CONFIG_FAIR_GROUP_SCHED，每个task_group在每个CPU上面维护了一个sched_entity和cfs_rq，sched_entity负责管理对应的cfs_rq并将其保存在自身的my_q里面
当cfs_rq里面有具体的task的时候，cfs_rq会被加入到对应rq的leaf_cfs_rq_list里面，并一直存在，直到对应的task_group被unregister

sched_stat_sleep: interruptible -> 入队
sched_stat_blocked: uninterruptible -> 入队 {
	sched_stat_iowait: 其中的io等待时间
}
sched_stat_wait: 入队 -> 执行的等待时间
sched_stat_runtime: 执行 -> switch的时间

load = time * scale_frequency * weight
load_avg = load_sum * weight / divider?
runnable_load
util = time * scale_frequency * scale_cpu (util不考虑权重，但是考虑CPU之间的差异)
LOAD_AVG_MAX计算平均值的时间长度ns，由于该时间无法完整的分割成n个取样周期，因此计算平均值的时候，除以(LOAD_AVG_MAX - 1024 + sa->period_contrib)
只要进入rq就计算为load，计算util的时候要看是否running

不同CPU在不同的frequency下的capacity如何校准？

struct sched_cluster用来描述一组具有相同能效的CPU



https://lwn.net/Articles/639543/

#1------------------------------------------------------------------------------
weight与load的概念 {
	task的优先级(nice/priority)通过sched_prio_to_weight转化为weight，nice=0的weight是1024
	对应的load在32位机器上和weight一致，在64位机器上则scale_up以提高精度(<<10)
	NICE_0_LOAD为默认task的load值
	struct load_weight结构中存储的weight都是scale_up之后的值
	struct sched_avg结构中的load_avg是scale_down之后的平均值(对于task，初始值就=scale_load_down(se->load.weight))
}
#2------------------------------------------------------------------------------
load, runnable, util {					task					group										cfs_rq
	weight表示权重						se->load.weight			tg->weight * grq->load_avg / tg->load_avg	Sum(se->load.weight) ???
	load表示负载						se->on_rq				se->on_rq									scale_load_down(cfs_rq->load.weight)
	runnable表示可运行的task的数量		se->on_rq				se->runnable_weight							cfs_rq->h_nr_running
	util表示使用率(是否running)			cfs_rq->curr == se		cfs_rq->curr == se							cfs_rq->curr != NULL
}
#3------------------------------------------------------------------------------
为什么se计算load_sum的时候不考虑se的weight，而计算load_avg的时候考虑se的weight，计算cfs_rq的时候又恰恰相反? {
	目前看所有的代码逻辑均遵从此原则，se的load_sum不考虑weight，但是计算se的load_avg的时候需要将weight应用上，对于se来说load_avg = load_sum / divider * weight
	而对于cfs_rq来说load_avg和load_sum存储的都是weight应用之后的结果
}
#4------------------------------------------------------------------------------
两个不同的group如何在多核系统上取得fair的效果? {
	group本身的share值表示其权重，通过计算分配到各cpu上的se
	参考#2中的group的weight计算
}
--------------------------------------------------------------------------------

task_struct {
	struct sched_entity     se; {
		struct load_weight      load; {
			unsigned long           weight;			#1
			u32             inv_weight;
		}
		unsigned int            on_rq;
		unsigned long           runnable_weight;
		struct sched_avg        avg; {
			u64             last_update_time;
			u64             load_sum;
			u64             runnable_sum;
			u32             util_sum;
			u32             period_contrib;
			unsigned long           load_avg;		#初始值scale_down(load.weight)
			unsigned long           runnable_avg;
			unsigned long           util_avg;
			struct util_est         util_est;
		}
	}
}
--------------------------------------------------------------------------------
sched_entity (task) {
                               se->on_rq           !se->on_rq
	weight                     weight              0
	runnable = weight          weight              0
    runnable_sum                     不考虑weight，根据pelt算法能够得出的最大sum按比例换算，percent% * LOAD_AVG_MAX?
    runnable_avg                     不考虑weight，percent% * scale
    load_sum                         = runnable_sum
    load_avg                         考虑weight，= weight * runnable_avg
}
sched_entity (group) {
}
cfs_rq {
}

load_(sum/avg) {load, (weight)} (on_rq的时候计算，否则不算)
runnable_(sum/avg) {可运行的task数量, (0,n)}
util_(sum/avg) {可运行的时间, (0,1)}
--------------------------------------------------------------------------------


cfs_rq->load.weight是所有on_rq的se的load汇总
cfs_rq->avg对于非on_rq的负载也会统计，因为存在于cfs_rq上的load都需要逐步decay到0，虽然某个se因为dequeue导致!on_rq，但是cfs_rq上关于该se的load的影响仍在(避免负载跳变？)，对于SMP，如果这个时候我们要把se迁移到另一个CPU，那么需要从原先的cfs_rq上将该se贡献的负载剔除，然后在新的CPU上面将该se的负载加上，这样对于多个CPU的负载总和没有跳变。
另一个要处理的case是se在cgroup之间迁移

tg->load_avg = sum(cfs_rq->tg_load_avg_contrib)，其中cfs_rq->tg_load_avg_contrib由cfs_rq->avg.load_avg每次跳变超过一定的范围更新而来。

__update_load_avg_blocked_se

fork
migrate
wakeup
sleep

cgroup change



activate_task, deactivate_task {
	将task(加入/移除/迁出)runqueue
}
